{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb0a714-9d15-41bc-ac06-ce5a1e448b1d",
   "metadata": {},
   "source": [
    "# Training Item Response Theory (IRT) models\n",
    "\n",
    "In this notebook, we show how to train your own Item Response Theory (IRT) models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7008d96d-1ee5-44cf-91cb-293fb3e048bf",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85d9b93-5059-416c-8a53-e3b4cc24a904",
   "metadata": {},
   "source": [
    "Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7892164d-f5bb-4cef-9f4f-685a9af85679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from irt import *\n",
    "from utils import *\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebb8ce2-1851-4131-8d35-36214be71085",
   "metadata": {},
   "source": [
    "The leaderboard dataset we will use is composed by six scenarios (sub-datasets):\n",
    "1. TruthfulQA\n",
    "1. GSM8K\n",
    "1. Winogrande\n",
    "1. ARC\n",
    "1. HellaSwag\n",
    "1. MMLU\n",
    "\n",
    "MMLU is further divided into sub-scenarios (e.g., abstract algebra, anatomy, etc). Let's check scenarios and sub-scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26499fc1-2bda-44b2-9131-e78d16f7f77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'harness_truthfulqa_mc_0': ['harness_truthfulqa_mc_0'],\n",
       " 'gsm8k': ['harness_gsm8k_5'],\n",
       " 'winogrande': ['harness_winogrande_5'],\n",
       " 'arc': ['harness_arc_challenge_25'],\n",
       " 'hellaswag': ['harness_hellaswag_10'],\n",
       " 'mmlu': ['harness_hendrycksTest_abstract_algebra_5',\n",
       "  'harness_hendrycksTest_anatomy_5',\n",
       "  'harness_hendrycksTest_astronomy_5',\n",
       "  'harness_hendrycksTest_business_ethics_5',\n",
       "  'harness_hendrycksTest_clinical_knowledge_5',\n",
       "  'harness_hendrycksTest_college_biology_5',\n",
       "  'harness_hendrycksTest_college_chemistry_5',\n",
       "  'harness_hendrycksTest_college_computer_science_5',\n",
       "  'harness_hendrycksTest_college_mathematics_5',\n",
       "  'harness_hendrycksTest_college_medicine_5',\n",
       "  'harness_hendrycksTest_college_physics_5',\n",
       "  'harness_hendrycksTest_computer_security_5',\n",
       "  'harness_hendrycksTest_conceptual_physics_5',\n",
       "  'harness_hendrycksTest_econometrics_5',\n",
       "  'harness_hendrycksTest_electrical_engineering_5',\n",
       "  'harness_hendrycksTest_elementary_mathematics_5',\n",
       "  'harness_hendrycksTest_formal_logic_5',\n",
       "  'harness_hendrycksTest_global_facts_5',\n",
       "  'harness_hendrycksTest_high_school_biology_5',\n",
       "  'harness_hendrycksTest_high_school_chemistry_5',\n",
       "  'harness_hendrycksTest_high_school_computer_science_5',\n",
       "  'harness_hendrycksTest_high_school_european_history_5',\n",
       "  'harness_hendrycksTest_high_school_geography_5',\n",
       "  'harness_hendrycksTest_high_school_government_and_politics_5',\n",
       "  'harness_hendrycksTest_high_school_macroeconomics_5',\n",
       "  'harness_hendrycksTest_high_school_mathematics_5',\n",
       "  'harness_hendrycksTest_high_school_microeconomics_5',\n",
       "  'harness_hendrycksTest_high_school_physics_5',\n",
       "  'harness_hendrycksTest_high_school_psychology_5',\n",
       "  'harness_hendrycksTest_high_school_statistics_5',\n",
       "  'harness_hendrycksTest_high_school_us_history_5',\n",
       "  'harness_hendrycksTest_high_school_world_history_5',\n",
       "  'harness_hendrycksTest_human_aging_5',\n",
       "  'harness_hendrycksTest_human_sexuality_5',\n",
       "  'harness_hendrycksTest_international_law_5',\n",
       "  'harness_hendrycksTest_jurisprudence_5',\n",
       "  'harness_hendrycksTest_logical_fallacies_5',\n",
       "  'harness_hendrycksTest_machine_learning_5',\n",
       "  'harness_hendrycksTest_management_5',\n",
       "  'harness_hendrycksTest_marketing_5',\n",
       "  'harness_hendrycksTest_medical_genetics_5',\n",
       "  'harness_hendrycksTest_miscellaneous_5',\n",
       "  'harness_hendrycksTest_moral_disputes_5',\n",
       "  'harness_hendrycksTest_moral_scenarios_5',\n",
       "  'harness_hendrycksTest_nutrition_5',\n",
       "  'harness_hendrycksTest_philosophy_5',\n",
       "  'harness_hendrycksTest_prehistory_5',\n",
       "  'harness_hendrycksTest_professional_accounting_5',\n",
       "  'harness_hendrycksTest_professional_law_5',\n",
       "  'harness_hendrycksTest_professional_medicine_5',\n",
       "  'harness_hendrycksTest_professional_psychology_5',\n",
       "  'harness_hendrycksTest_public_relations_5',\n",
       "  'harness_hendrycksTest_security_studies_5',\n",
       "  'harness_hendrycksTest_sociology_5',\n",
       "  'harness_hendrycksTest_us_foreign_policy_5',\n",
       "  'harness_hendrycksTest_virology_5',\n",
       "  'harness_hendrycksTest_world_religions_5']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9d88f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_SCENARIOS = ['gsm8k', 'arc', 'hellaswag', 'harness_truthfulqa_mc_0']\n",
    "\n",
    "# select gsm8k, arc, hellaswag\n",
    "lb_scenarios = {'lb': []}\n",
    "for scenario in scenarios.keys():\n",
    "    if scenario in SELECTED_SCENARIOS:\n",
    "        lb_scenarios['lb'].append(*scenarios[scenario])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34e5620-bd45-4985-b390-a154843b4d6c",
   "metadata": {},
   "source": [
    "Loading leaderboard data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ca68f5c-49de-4f75-92e5-de639059cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/lb_scenarios.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "    data['models'] = data['models'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f14f180-d322-4cd5-8d0c-4ae4fef04127",
   "metadata": {},
   "source": [
    "In this dataset, we have data from 395 models. Let's see the names of some of them below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d6c4201-0675-42e5-8a7a-8cf75592e661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393,\n",
       " ['open-llm-leaderboard/details_moreh__MoMo-70B-lora-1.8.6-DPO',\n",
       "  'open-llm-leaderboard/details_cloudyu__Yi-34Bx3-MoE-90B',\n",
       "  'open-llm-leaderboard/details_Weyaxi__Helion-4x34B',\n",
       "  'open-llm-leaderboard/details_Weyaxi__Bagel-Hermes-34B-Slerp',\n",
       "  'open-llm-leaderboard/details_Weyaxi__Bagel-Hermes-2x34b',\n",
       "  'open-llm-leaderboard/details_nfaheem__Marcoroni-7b-DPO-Merge',\n",
       "  'open-llm-leaderboard/details_jondurbin__bagel-dpo-34b-v0.2',\n",
       "  'open-llm-leaderboard/details_udkai__Turdus',\n",
       "  'open-llm-leaderboard/details_gagan3012__MetaModel_moe',\n",
       "  'open-llm-leaderboard/details_jeonsworld__CarbonVillain-en-10.7B-v3'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['models']), data['models'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d8135b-e9ec-468a-85a7-3cd3fc3d31fe",
   "metadata": {},
   "source": [
    "Below, we will process the data so all correctness scores (for all scenarios) are stored in $Y$. The dictionaries `scenarios_position` and `subscenarios_position` give the position of scenarios/subscenarios correctness scores in $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee09c25b-2dc4-4403-a972-9fb05cfe917b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393, 13350)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios_position, subscenarios_position = prepare_data(lb_scenarios, data)\n",
    "Y = create_responses(lb_scenarios, data)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eec0522b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['harness_truthfulqa_mc_0', 'harness_gsm8k_5', 'harness_arc_challenge_25', 'harness_hellaswag_10'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subscenarios_position['lb'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a8764bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y stats:\n",
      "min: 0.0\n",
      "max: 1.0000000000000002\n",
      "mean: 0.7231160348021274\n",
      "std: 0.443520043003996\n"
     ]
    }
   ],
   "source": [
    "# fill nan values with 0\n",
    "Y[np.isnan(Y)] = 0\n",
    "\n",
    "# print stats of Y\n",
    "print('Y stats:')\n",
    "print('min:', np.min(Y))\n",
    "print('max:', np.max(Y))\n",
    "print('mean:', np.mean(Y))\n",
    "print('std:', np.std(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e002485a-1e82-409b-aaf2-ddb6a82bc315",
   "metadata": {},
   "source": [
    "For example, below you can see the scores for MMLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4dd9649-ba75-49c0-92fe-b00d2afc252e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.99999999, 0.99994655, 1.        , ..., 1.        , 0.        ,\n",
       "         1.        ],\n",
       "        [0.99984026, 0.99999999, 0.99908489, ..., 1.        , 1.        ,\n",
       "         1.        ],\n",
       "        [0.99937792, 0.99999997, 0.99732544, ..., 1.        , 1.        ,\n",
       "         1.        ],\n",
       "        ...,\n",
       "        [0.59677787, 0.99801392, 0.20934594, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.67288482, 0.99814252, 0.3865014 , ..., 0.        , 1.        ,\n",
       "         1.        ],\n",
       "        [0.42345796, 0.99926741, 0.82057698, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " (393, 13350))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:,scenarios_position['lb']], Y[:,scenarios_position['lb']].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d062bc-1efe-4527-b40c-96fc295e05fe",
   "metadata": {},
   "source": [
    "For scenarios that have multiple subscenarios, it is usually the case that we want to give equal importance to individual subscenarios when computing the aggregated performance in that scenario. This is equivalent to using a weighted average when computing the aggregated performance. We will create balance_weights, a vector of weights to help us compute those weighted averages. These weights will be different than one only for MMLU, which is the only scenario with multiple subscenarios.\n",
    "\n",
    "We will use this when choosing the IRT dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25c2e717-c575-4b0c-8067-15574c3dde3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_weights = np.ones(Y.shape[1])\n",
    "\n",
    "selected_scenarios = lb_scenarios['lb']\n",
    "\n",
    "N = len(scenarios_position['lb'])\n",
    "n_sub = len(selected_scenarios)\n",
    "for sub in selected_scenarios:\n",
    "    n_i = len(subscenarios_position['lb'][sub])\n",
    "    balance_weights[subscenarios_position['lb'][sub]] = N/(n_sub*n_i)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4dd3af-2d50-4ed5-bc36-09acf3f987fc",
   "metadata": {},
   "source": [
    "We can see below that first averaging within subscenarios and then computing a simple average is equivalent to using a weighted average from the beginning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85903718-e30c-433b-b407-74fc9ebb05eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1356762293373007e-14"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs1 = np.mean([Y[:,subscenarios_position['lb'][sub]].mean(axis=1) for sub in lb_scenarios['lb']], axis=0)\n",
    "accs2 = (balance_weights*Y)[:,scenarios_position['lb']].mean(axis=1)\n",
    "\n",
    "np.abs(accs1 - accs2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d106b620-7fe0-49bb-a8ac-3a946c15f751",
   "metadata": {},
   "source": [
    "## Training IRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844c4412-ae69-4184-b106-191a1c151736",
   "metadata": {},
   "source": [
    "Let's split the data in train and test (recent models are placed in the test set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc9874c5-7cb5-425b-8c41-9a87d7615ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = Y[:100]\n",
    "Y_train = Y[100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e856d5-3778-417f-b4e9-77cfc9f6e6a1",
   "metadata": {},
   "source": [
    "To train the IRT model, we first need to binarize the values in $Y$ because correctness is not binary for TruthfulQA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "739556a1-fd5c-4edb-8fd2-2e0914377eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 59.16it/s]\n"
     ]
    }
   ],
   "source": [
    "Y_bin_train = np.zeros(Y_train.shape)\n",
    "Y_bin_test = np.zeros(Y_test.shape)\n",
    "\n",
    "cs = np.linspace(0.01,.99,100)  # Threshold values to consider\n",
    "for scenario in lb_scenarios.keys():\n",
    "    ind = scenarios_position[scenario]\n",
    "    # Find the best threshold value that minimizes the difference between averages\n",
    "    c = cs[np.argmin([np.mean((np.abs((Y_train[:,ind]>c).mean(axis=1)-Y_train[:,ind].mean(axis=1)))) for c in tqdm(cs)])]\n",
    "    # Apply the threshold to train and test responses\n",
    "    Y_bin_train[:,ind] = (Y_train[:,ind]>c).astype(int)\n",
    "    Y_bin_test[:,ind] = (Y_test[:,ind]>c).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964dbee2-3607-4f6a-b287-29f12b5e20d5",
   "metadata": {},
   "source": [
    "Choosing the dimension for the IRT model based on a simple validation heuristic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9999beb9-9796-45ea-993b-cd293d343002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:33:08] config: model_type='multidim_2pl' epochs=2000              cli.py:109\n",
      "           priors='hierarchical' initializers=[] dims=2 lr=0.1                  \n",
      "           lr_decay=0.9999 dropout=0.5 hidden=100 vocab_size=None               \n",
      "           log_every=200 seed=42 deterministic=True                             \n",
      "           data_path: data/irt_val_dataset.jsonlines                  cli.py:111\n",
      "           output directory: data/irt_val_model/                      cli.py:112\n",
      "[20:33:08] amortized: False                                       dataset.py:112\n",
      "[20:33:17] Vocab size: None                                       training.py:90\n",
      "[20:33:17] Training Model...                                          cli.py:116\n",
      "           args: {'device': 'cuda', 'num_items': 13350,          training.py:134\n",
      "           'num_subjects': 234}                                                 \n",
      "           Parsed Model Args: {'device': 'cuda', 'num_items':    training.py:147\n",
      "           13350, 'num_subjects': 234, 'priors': 'hierarchical',                \n",
      "           'dims': 2, 'dropout': 0.5, 'hidden': 100,                            \n",
      "           'vocab_size': None}                                                  \n",
      "torch.Size([3123900]) torch.Size([3123900])\n",
      "Training Pyro IRT Model for 2000 epochs\n",
      "┏━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
      "┃ Epoch ┃ Loss         ┃ Best Loss    ┃ New LR ┃\n",
      "┡━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
      "│ 1     │ 3817437.1052 │ 3817437.1052 │ 0.1000 │\n",
      "│ 201   │ 612297.9903  │ 612297.9903  │ 0.0980 │\n",
      "│ 401   │ 609420.3584  │ 606943.7662  │ 0.0961 │\n",
      "│ 601   │ 609051.8670  │ 605983.7124  │ 0.0942 │\n",
      "│ 801   │ 606108.4034  │ 605520.3136  │ 0.0923 │\n",
      "│ 1001  │ 606214.3798  │ 605237.3374  │ 0.0905 │\n",
      "│ 1201  │ 605984.5394  │ 605088.5979  │ 0.0887 │\n",
      "│ 1401  │ 605455.6201  │ 604952.4649  │ 0.0869 │\n",
      "│ 1601  │ 606148.6164  │ 604952.4649  │ 0.0852 │\n",
      "│ 1801  │ 606512.3019  │ 604805.4593  │ 0.0835 │\n",
      "│ 2000  │ 605306.1580  │ 604805.4593  │ 0.0819 │\n",
      "��───────┴──────────────┴──────────────┴────────┘[20:34:01] Train time: 53.49847626686096                              cli.py:122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:56<02:49, 56.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:34:04] config: model_type='multidim_2pl' epochs=2000              cli.py:109\n",
      "           priors='hierarchical' initializers=[] dims=5 lr=0.1                  \n",
      "           lr_decay=0.9999 dropout=0.5 hidden=100 vocab_size=None               \n",
      "           log_every=200 seed=42 deterministic=True                             \n",
      "           data_path: data/irt_val_dataset.jsonlines                  cli.py:111\n",
      "           output directory: data/irt_val_model/                      cli.py:112\n",
      "[20:34:05] amortized: False                                       dataset.py:112\n",
      "[20:34:12] Vocab size: None                                       training.py:90\n",
      "[20:34:13] Training Model...                                          cli.py:116\n",
      "[20:34:13] args: {'device': 'cuda', 'num_items': 13350,          training.py:134\n",
      "           'num_subjects': 234}                                                 \n",
      "           Parsed Model Args: {'device': 'cuda', 'num_items':    training.py:147\n",
      "           13350, 'num_subjects': 234, 'priors': 'hierarchical',                \n",
      "           'dims': 5, 'dropout': 0.5, 'hidden': 100,                            \n",
      "           'vocab_size': None}                                                  \n",
      "torch.Size([3123900]) torch.Size([3123900])\n",
      "Training Pyro IRT Model for 2000 epochs\n",
      "┏━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
      "┃ Epoch ┃ Loss         ┃ Best Loss    ┃ New LR ┃\n",
      "┡━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
      "│ 1     │ 7276231.1488 │ 7276231.1488 │ 0.1000 │\n",
      "│ 201   │ 592085.3411  │ 592085.3411  │ 0.0980 │\n",
      "│ 401   │ 582311.3315  │ 577946.9188  │ 0.0961 │\n",
      "│ 601   │ 584011.8948  │ 574534.4042  │ 0.0942 │\n",
      "│ 801   │ 574144.6580  │ 572750.0555  │ 0.0923 │\n",
      "│ 1001  │ 576786.0080  │ 571733.8882  │ 0.0905 │\n",
      "│ 1201  │ 572393.2848  │ 571294.6753  │ 0.0887 │\n",
      "│ 1401  │ 571995.6448  │ 571172.1424  │ 0.0869 │\n",
      "│ 1601  │ 573315.1611  │ 571136.4630  │ 0.0852 │\n",
      "│ 1801  │ 573090.9409  │ 571107.9906  │ 0.0835 │\n",
      "│ 2000  │ 571673.4052  │ 570913.6139  │ 0.0819 │\n",
      "��───────┴──────────────┴──────────────┴────────┘[20:35:00] Train time: 56.02738833427429                              cli.py:122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [01:58<01:59, 59.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:35:06] config: model_type='multidim_2pl' epochs=2000              cli.py:109\n",
      "           priors='hierarchical' initializers=[] dims=10 lr=0.1                 \n",
      "           lr_decay=0.9999 dropout=0.5 hidden=100 vocab_size=None               \n",
      "           log_every=200 seed=42 deterministic=True                             \n",
      "           data_path: data/irt_val_dataset.jsonlines                  cli.py:111\n",
      "           output directory: data/irt_val_model/                      cli.py:112\n",
      "[20:35:06] amortized: False                                       dataset.py:112\n",
      "[20:35:14] Vocab size: None                                       training.py:90\n",
      "[20:35:14] Training Model...                                          cli.py:116\n",
      "           args: {'device': 'cuda', 'num_items': 13350,          training.py:134\n",
      "           'num_subjects': 234}                                                 \n",
      "           Parsed Model Args: {'device': 'cuda', 'num_items':    training.py:147\n",
      "           13350, 'num_subjects': 234, 'priors': 'hierarchical',                \n",
      "           'dims': 10, 'dropout': 0.5, 'hidden': 100,                           \n",
      "           'vocab_size': None}                                                  \n",
      "torch.Size([3123900]) torch.Size([3123900])\n",
      "Training Pyro IRT Model for 2000 epochs\n"
     ]
    }
   ],
   "source": [
    "Ds = [2,5,10,15] # Dimensions to try\n",
    "device = 'cuda' # Either 'cuda' or 'cpu' \n",
    "epochs = 2000  # Number of epochs for IRT model training (py-irt default is 2000)\n",
    "lr = .1  # Learning rate for IRT model training (py-irt default is .1)\n",
    "\n",
    "val_ind = list(range(0,Y_bin_train.shape[0],5)) # Validation indices\n",
    "train_ind = [i for i in range(Y_bin_train.shape[0]) if i not in val_ind]\n",
    "\n",
    "# Saving the training dataset in the needed format\n",
    "create_irt_dataset(Y_bin_train[train_ind], 'data/irt_val_dataset.jsonlines')\n",
    "\n",
    "# Trying different Ds\n",
    "errors = []  \n",
    "errors2 = []\n",
    "\n",
    "for D in tqdm(Ds):\n",
    "    dataset_name = 'data/irt_val_dataset.jsonlines'\n",
    "    model_name = 'data/irt_val_model/'\n",
    "    \n",
    "    # Load trained IRT model parameters\n",
    "    train_irt_model(dataset_name, model_name, D, lr, epochs, device)\n",
    "    A, B, Theta = load_irt_parameters(model_name)\n",
    "    \n",
    "    # Determine seen and unseen items for validation\n",
    "    seen_items = list(range(0, Y_bin_train.shape[1], 2))\n",
    "    unseen_items = list(range(1, Y_bin_train.shape[1], 2))\n",
    "\n",
    "    # Estimate ability parameters for the validation set\n",
    "    thetas = [estimate_ability_parameters(Y_bin_train[val_ind][j][seen_items], A[:, :, seen_items], B[:, :, seen_items]) for j in range(len(val_ind))]\n",
    "\n",
    "    # Compute validation errors for each scenario and update the errors list (in the end, we give the same weight for all scenarios)\n",
    "    errors2.append([])\n",
    "    for scenario in lb_scenarios.keys():\n",
    "        ind = [u for u in unseen_items if u in scenarios_position[scenario]]\n",
    "        errors2[-1].append(np.mean([abs((balance_weights*item_curve(thetas[j], A, B))[0,ind].mean()-Y_train[val_ind][j,ind].mean())for j in range(len(val_ind))]))\n",
    "    errors.append(np.mean(errors2[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efbdc2b3-fb4e-4075-b1df-a747ce7d68e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_D = np.argmin(np.array(errors))\n",
    "D = Ds[ind_D]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8680d6e6-1ec2-4a24-a898-f29bd5ec109e",
   "metadata": {},
   "source": [
    "Saving the training dataset in the needed format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4a80e3b-8e0c-402f-8263-7e178b976bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_irt_dataset(Y_bin_train, 'data/irt_dataset.jsonlines')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aa8114-a6b3-493c-8220-9f8976131a53",
   "metadata": {},
   "source": [
    "To train the IRT model, we use an adapted version of `py-irt` code (please check README in the tutorials directory for mode details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7dcda49-4f05-4350-9dcf-d09addc8f983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:43:13] config: model_type='multidim_2pl' epochs=2000              cli.py:109\n",
      "           priors='hierarchical' initializers=[] dims=10 lr=0.1                 \n",
      "           lr_decay=0.9999 dropout=0.5 hidden=100 vocab_size=None               \n",
      "           log_every=200 seed=42 deterministic=True                             \n",
      "           data_path: data/irt_dataset.jsonlines                      cli.py:111\n",
      "           output directory: data/irt_model                           cli.py:112\n",
      "[18:43:14] amortized: False                                       dataset.py:112\n",
      "[18:43:23] Vocab size: None                                       training.py:90\n",
      "[18:43:24] Training Model...                                          cli.py:116\n",
      "[18:43:24] args: {'device': 'cuda', 'num_items': 13350,          training.py:134\n",
      "           'num_subjects': 293}                                                 \n",
      "           Parsed Model Args: {'device': 'cuda', 'num_items':    training.py:147\n",
      "           13350, 'num_subjects': 293, 'priors': 'hierarchical',                \n",
      "           'dims': 10, 'dropout': 0.5, 'hidden': 100,                           \n",
      "           'vocab_size': None}                                                  \n",
      "torch.Size([3911550]) torch.Size([3911550])\n",
      "Training Pyro IRT Model for 2000 epochs\n",
      "┏━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
      "┃ Epoch ┃ Loss          ┃ Best Loss     ┃ New LR ┃\n",
      "┡━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
      "│ 1     │ 16769378.9309 │ 16769378.9309 │ 0.1000 │\n",
      "│ 201   │ 785845.2478   │ 779191.6874   │ 0.0980 │\n",
      "│ 401   │ 726335.3750   │ 724337.2936   │ 0.0961 │\n",
      "│ 601   │ 724025.6020   │ 711787.3617   │ 0.0942 │\n",
      "│ 801   │ 705973.3244   │ 704644.8113   │ 0.0923 │\n",
      "│ 1001  │ 705768.9756   │ 701016.2078   │ 0.0905 │\n",
      "│ 1201  │ 702360.5824   │ 698436.9638   │ 0.0887 │\n",
      "│ 1401  │ 699063.3629   │ 697849.4475   │ 0.0869 │\n",
      "│ 1601  │ 699099.4459   │ 697181.1498   │ 0.0852 │\n",
      "│ 1801  │ 698719.8970   │ 696386.8139   │ 0.0835 │\n",
      "│ 2000  │ 697465.7690   │ 696121.5267   │ 0.0819 │\n",
      "└───────┴───────────────┴───────────────┴────────┘[18:44:25] Train time: 71.57253909111023                              cli.py:122\n"
     ]
    }
   ],
   "source": [
    "train_irt_model(dataset_name='data/irt_dataset.jsonlines', \n",
    "                model_name='data/irt_model', \n",
    "                D=D, lr=lr, epochs=epochs, device=device)               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0f46f1",
   "metadata": {},
   "source": [
    "## Get the values for $\\lambda$ which will be used to get the gp-IRT estimates (in conjunction with anchor methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e186b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lambda(b, v):\n",
    "    return (b**2)/(v+(b**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c5c76c",
   "metadata": {},
   "source": [
    "The variable `number_item` gives the number of data points we will sample per scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd9962b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_item = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b2fd007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_lambdas(errors2, Y_train, scenarios_position, lb_scenarios, number_item):\n",
    "    lambds = {} \n",
    "\n",
    "    for i,scenario in enumerate(lb_scenarios.keys()):\n",
    "        v = np.var(Y_train[:,scenarios_position[scenario]], axis=1).mean()\n",
    "        b = np.mean(errors2[ind_D][i]) \n",
    "        lambds[scenario] = get_lambda(b, v/(4*number_item))\n",
    "\n",
    "    return lambds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b270a850",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_item in [10, 15, 20, 30, 50]:\n",
    "    lambds = estimate_lambdas(errors2, Y_train, scenarios_position, lb_scenarios, num_item)\n",
    "    \n",
    "    # read lb_anchor_{num_item}.pickle file\n",
    "    with open(f'data/lb_anchor_{num_item}.pickle', 'rb') as handle:\n",
    "        anchor_data = pickle.load(handle) # contains 'seen_examples', 'examples_weights', 'scenarios_position', 'subscenarios_position'\n",
    "    # save to tinybenchmark_lb file, putting 'seen_examples', 'examples_weights', 'irt_parameters', 'scenarios_position', 'subscenarios_position', 'optimal_lambdas'\n",
    "    with open(f'data/tinybenchmark_lb_{num_item}.pickle', 'wb') as handle:\n",
    "        pickle.dump({'seen_examples': anchor_data['seen_examples'], \n",
    "                     'examples_weights': anchor_data['examples_weights'], \n",
    "                     'irt_parameters': {'A': A, 'B': B}, \n",
    "                     'scenarios_position': anchor_data['scenarios_position'], \n",
    "                     'subscenarios_position': anchor_data['subscenarios_position'], \n",
    "                     'optimal_lambdas': lambds}, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa798002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'harness_truthfulqa_mc_0': array([305,  77, 532, 788, 231, 746, 715, 454, 354, 411, 249, 728, 260,\n",
       "        448,  21,  66,  60, 545, 520, 457, 633, 559, 399, 758, 160, 196,\n",
       "        668, 273, 636,  82, 566, 546, 292,  92, 666, 711, 561, 644, 127,\n",
       "        518, 271, 234, 699, 171, 449, 186, 491,  96, 219, 496]),\n",
       " 'harness_gsm8k_5': array([ 494, 1257,   75,  236, 1290,  906,  675,   83,  956,   38,  683,\n",
       "        1234,  664, 1187, 1239,  331, 1141,  427,  311,  943,  144,  834,\n",
       "         536,  362, 1112,  945, 1140, 1103, 1272,  863,  506,  638,  490,\n",
       "         251,  196,  217,  442,  794,  723,  435, 1011,  775,  198,  999,\n",
       "          90,  473, 1284,  990,  980, 1224]),\n",
       " 'harness_arc_challenge_25': array([ 339,  672, 1140, 1136,  787,  512, 1082,  182,   31,   35, 1132,\n",
       "         126,  228,  412,   87,  131,  693,   70,  270, 1160,  832, 1063,\n",
       "         692,   58, 1047,  435,  753,  613,  422,  585, 1065, 1151,  309,\n",
       "         821,  679,   14,  929, 1022,  906,  397, 1033, 1153,  184,  266,\n",
       "         757,  104,  442,  465,  254,  730]),\n",
       " 'harness_hellaswag_10': array([3930, 9174, 9924,  621, 8218, 4431, 8621, 7738, 7318, 8435, 8503,\n",
       "         346, 5274, 8575, 4659, 6022, 9639, 9877, 9523, 5225, 3844, 3216,\n",
       "         379, 1338, 6375, 7780, 5349, 6315, 8285, 6736, 7863, 3242, 6192,\n",
       "        6387, 7092, 5207, 9395, 9929, 6832, 8985, 2641, 1560, 6261, 9664,\n",
       "        4352, 6306, 7584,  683, 4779, 3717])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_data['seen_examples']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
