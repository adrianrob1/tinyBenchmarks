{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb0a714-9d15-41bc-ac06-ce5a1e448b1d",
   "metadata": {},
   "source": [
    "# Finding and using anchor points\n",
    "\n",
    "In this notebook, we show how to find anchor points based on your training set and how to use them to estimate the performance of new models in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7008d96d-1ee5-44cf-91cb-293fb3e048bf",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85d9b93-5059-416c-8a53-e3b4cc24a904",
   "metadata": {},
   "source": [
    "Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7892164d-f5bb-4cef-9f4f-685a9af85679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from irt import *\n",
    "from utils import *\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebb8ce2-1851-4131-8d35-36214be71085",
   "metadata": {},
   "source": [
    "The leaderboard dataset we will use is composed by six scenarios (sub-datasets):\n",
    "1. TruthfulQA\n",
    "1. GSM8K\n",
    "1. Winogrande\n",
    "1. ARC\n",
    "1. HellaSwag\n",
    "1. MMLU\n",
    "\n",
    "MMLU is further divided into sub-scenarios (e.g., abstract algebra, anatomy, etc). Let's check scenarios and sub-scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9810bb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'harness_truthfulqa_mc_0': ['harness_truthfulqa_mc_0'],\n",
       " 'gsm8k': ['harness_gsm8k_5'],\n",
       " 'winogrande': ['harness_winogrande_5'],\n",
       " 'arc': ['harness_arc_challenge_25'],\n",
       " 'hellaswag': ['harness_hellaswag_10'],\n",
       " 'mmlu': ['harness_hendrycksTest_abstract_algebra_5',\n",
       "  'harness_hendrycksTest_anatomy_5',\n",
       "  'harness_hendrycksTest_astronomy_5',\n",
       "  'harness_hendrycksTest_business_ethics_5',\n",
       "  'harness_hendrycksTest_clinical_knowledge_5',\n",
       "  'harness_hendrycksTest_college_biology_5',\n",
       "  'harness_hendrycksTest_college_chemistry_5',\n",
       "  'harness_hendrycksTest_college_computer_science_5',\n",
       "  'harness_hendrycksTest_college_mathematics_5',\n",
       "  'harness_hendrycksTest_college_medicine_5',\n",
       "  'harness_hendrycksTest_college_physics_5',\n",
       "  'harness_hendrycksTest_computer_security_5',\n",
       "  'harness_hendrycksTest_conceptual_physics_5',\n",
       "  'harness_hendrycksTest_econometrics_5',\n",
       "  'harness_hendrycksTest_electrical_engineering_5',\n",
       "  'harness_hendrycksTest_elementary_mathematics_5',\n",
       "  'harness_hendrycksTest_formal_logic_5',\n",
       "  'harness_hendrycksTest_global_facts_5',\n",
       "  'harness_hendrycksTest_high_school_biology_5',\n",
       "  'harness_hendrycksTest_high_school_chemistry_5',\n",
       "  'harness_hendrycksTest_high_school_computer_science_5',\n",
       "  'harness_hendrycksTest_high_school_european_history_5',\n",
       "  'harness_hendrycksTest_high_school_geography_5',\n",
       "  'harness_hendrycksTest_high_school_government_and_politics_5',\n",
       "  'harness_hendrycksTest_high_school_macroeconomics_5',\n",
       "  'harness_hendrycksTest_high_school_mathematics_5',\n",
       "  'harness_hendrycksTest_high_school_microeconomics_5',\n",
       "  'harness_hendrycksTest_high_school_physics_5',\n",
       "  'harness_hendrycksTest_high_school_psychology_5',\n",
       "  'harness_hendrycksTest_high_school_statistics_5',\n",
       "  'harness_hendrycksTest_high_school_us_history_5',\n",
       "  'harness_hendrycksTest_high_school_world_history_5',\n",
       "  'harness_hendrycksTest_human_aging_5',\n",
       "  'harness_hendrycksTest_human_sexuality_5',\n",
       "  'harness_hendrycksTest_international_law_5',\n",
       "  'harness_hendrycksTest_jurisprudence_5',\n",
       "  'harness_hendrycksTest_logical_fallacies_5',\n",
       "  'harness_hendrycksTest_machine_learning_5',\n",
       "  'harness_hendrycksTest_management_5',\n",
       "  'harness_hendrycksTest_marketing_5',\n",
       "  'harness_hendrycksTest_medical_genetics_5',\n",
       "  'harness_hendrycksTest_miscellaneous_5',\n",
       "  'harness_hendrycksTest_moral_disputes_5',\n",
       "  'harness_hendrycksTest_moral_scenarios_5',\n",
       "  'harness_hendrycksTest_nutrition_5',\n",
       "  'harness_hendrycksTest_philosophy_5',\n",
       "  'harness_hendrycksTest_prehistory_5',\n",
       "  'harness_hendrycksTest_professional_accounting_5',\n",
       "  'harness_hendrycksTest_professional_law_5',\n",
       "  'harness_hendrycksTest_professional_medicine_5',\n",
       "  'harness_hendrycksTest_professional_psychology_5',\n",
       "  'harness_hendrycksTest_public_relations_5',\n",
       "  'harness_hendrycksTest_security_studies_5',\n",
       "  'harness_hendrycksTest_sociology_5',\n",
       "  'harness_hendrycksTest_us_foreign_policy_5',\n",
       "  'harness_hendrycksTest_virology_5',\n",
       "  'harness_hendrycksTest_world_religions_5']}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "26499fc1-2bda-44b2-9131-e78d16f7f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_SCENARIOS = ['gsm8k', 'arc', 'hellaswag', 'harness_truthfulqa_mc_0']\n",
    "\n",
    "# select gsm8k, arc, hellaswag\n",
    "lb_scenarios = {'lb': []}\n",
    "for scenario in scenarios.keys():\n",
    "    if scenario in SELECTED_SCENARIOS:\n",
    "        lb_scenarios['lb'].append(*scenarios[scenario])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34e5620-bd45-4985-b390-a154843b4d6c",
   "metadata": {},
   "source": [
    "Loading leaderboard data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2ca68f5c-49de-4f75-92e5-de639059cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('data/lb.pickle', 'rb') as handle:\n",
    "#    data = pickle.load(handle)\n",
    "with open('data/lb_scenarios.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d5058b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "harness_hellaswag_10\n",
      "Number of nan values in data: 0\n",
      "harness_truthfulqa_mc_0\n",
      "Number of nan values in data: 104\n",
      "harness_arc_challenge_25\n",
      "Number of nan values in data: 0\n",
      "harness_gsm8k_5\n",
      "Number of nan values in data: 0\n"
     ]
    }
   ],
   "source": [
    "for s in data['data'].keys():\n",
    "    print(s)\n",
    "    print('Number of nan values in data:', np.sum(np.isnan(data['data'][s]['correctness'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f14f180-d322-4cd5-8d0c-4ae4fef04127",
   "metadata": {},
   "source": [
    "In this dataset, we have data from 395 models. Let's see the names of some of them below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8382445d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lb': ['harness_truthfulqa_mc_0',\n",
       "  'harness_gsm8k_5',\n",
       "  'harness_arc_challenge_25',\n",
       "  'harness_hellaswag_10']}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb_scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5d6c4201-0675-42e5-8a7a-8cf75592e661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " [['open-llm-leaderboard/details_moreh__MoMo-70B-lora-1.8.6-DPO',\n",
       "   'open-llm-leaderboard/details_cloudyu__Yi-34Bx3-MoE-90B',\n",
       "   'open-llm-leaderboard/details_Weyaxi__Helion-4x34B',\n",
       "   'open-llm-leaderboard/details_Weyaxi__Bagel-Hermes-34B-Slerp',\n",
       "   'open-llm-leaderboard/details_Weyaxi__Bagel-Hermes-2x34b',\n",
       "   'open-llm-leaderboard/details_nfaheem__Marcoroni-7b-DPO-Merge',\n",
       "   'open-llm-leaderboard/details_jondurbin__bagel-dpo-34b-v0.2',\n",
       "   'open-llm-leaderboard/details_udkai__Turdus',\n",
       "   'open-llm-leaderboard/details_gagan3012__MetaModel_moe',\n",
       "   'open-llm-leaderboard/details_jeonsworld__CarbonVillain-en-10.7B-v3',\n",
       "   'open-llm-leaderboard/details_TomGrc__FusionNet',\n",
       "   'open-llm-leaderboard/details_kekmodel__StopCarbon-10.7B-v6',\n",
       "   'open-llm-leaderboard/details_jeonsworld__CarbonVillain-en-10.7B-v1',\n",
       "   'open-llm-leaderboard/details_Weyaxi__SauerkrautLM-UNA-SOLAR-Instruct',\n",
       "   'open-llm-leaderboard/details_VAGOsolutions__SauerkrautLM-SOLAR-Instruct',\n",
       "   'open-llm-leaderboard/details_bhavinjawade__SOLAR-10B-Nector-DPO-Jawade',\n",
       "   'open-llm-leaderboard/details_kyujinpy__Sakura-SOLAR-Instruct-DPO-v2',\n",
       "   'open-llm-leaderboard/details_fblgit__UNA-SOLAR-10.7B-Instruct-v1.0',\n",
       "   'open-llm-leaderboard/details_kyujinpy__Sakura-SOLRCA-Instruct-DPO',\n",
       "   'open-llm-leaderboard/details_zhengr__MixTAO-7Bx2-MoE-DPO',\n",
       "   'open-llm-leaderboard/details_Weyaxi__Nous-Hermes-2-SUS-Chat-2x34B',\n",
       "   'open-llm-leaderboard/details_NousResearch__Nous-Hermes-2-Yi-34B',\n",
       "   'open-llm-leaderboard/details_flemmingmiguel__NeuDist-Ro-7B',\n",
       "   'open-llm-leaderboard/details_mlabonne__NeuralMarcoro14-7B',\n",
       "   'open-llm-leaderboard/details_cookinai__BruinHermes',\n",
       "   'open-llm-leaderboard/details_shadowml__Daredevil-7B',\n",
       "   'open-llm-leaderboard/details_zyh3826__GML-Mistral-merged-v1',\n",
       "   'open-llm-leaderboard/details_Sao10K__WinterGoddess-1.4x-70B-L2',\n",
       "   'open-llm-leaderboard/details_CultriX__MistralTrixTest',\n",
       "   'open-llm-leaderboard/details_rombodawg__Open_Gpt4_8x7B',\n",
       "   'open-llm-leaderboard/details_shadowml__Marcoro14-7B-ties',\n",
       "   'open-llm-leaderboard/details_VAGOsolutions__SauerkrautLM-Mixtral-8x7B-Instruct',\n",
       "   'open-llm-leaderboard/details_PSanni__MPOMixtral-8x7B-Instruct-v0.1',\n",
       "   'open-llm-leaderboard/details_maywell__PiVoT-SUS-RP',\n",
       "   'open-llm-leaderboard/details_rwitz2__pee',\n",
       "   'open-llm-leaderboard/details_Brillibits__Instruct_Mixtral-8x7B-v0.1_Dolly15K',\n",
       "   'open-llm-leaderboard/details_mindy-labs__mindy-7b',\n",
       "   'open-llm-leaderboard/details_janhq__supermario-slerp',\n",
       "   'open-llm-leaderboard/details_rishiraj__CatPPT-base',\n",
       "   'open-llm-leaderboard/details_SanjiWatsuki__Kunoichi-7B',\n",
       "   'open-llm-leaderboard/details_brucethemoose__Yi-34B-200K-DARE-merge-v5',\n",
       "   'open-llm-leaderboard/details_AA051611__A0110',\n",
       "   'open-llm-leaderboard/details_Weyaxi__openchat-3.5-1210-Seraph-Slerp',\n",
       "   'open-llm-leaderboard/details_SanjiWatsuki__Loyal-Macaroni-Maid-7B',\n",
       "   'open-llm-leaderboard/details_AA051610__A0106',\n",
       "   'open-llm-leaderboard/details_PulsarAI__OpenHermes-2.5-neural-chat-v3-3-Slerp',\n",
       "   'open-llm-leaderboard/details_Walmart-the-bag__Solar-10.7B-Cato',\n",
       "   'open-llm-leaderboard/details_Weyaxi__OpenHermes-2.5-neural-chat-v3-3-openchat-3.5-1210-Slerp',\n",
       "   'open-llm-leaderboard/details_Intel__neural-chat-7b-v3-3-Slerp',\n",
       "   'open-llm-leaderboard/details_KnutJaegersberg__Deacon-34b-Adapter',\n",
       "   'open-llm-leaderboard/details_TomGrc__FusionNet_SOLAR',\n",
       "   'open-llm-leaderboard/details_superlazycoder__NeuralPipe-7B-slerp',\n",
       "   'open-llm-leaderboard/details_NousResearch__Nous-Hermes-2-SOLAR-10.7B',\n",
       "   'open-llm-leaderboard/details_chanwit__flux-7b-v0.1',\n",
       "   'open-llm-leaderboard/details_one-man-army__una-neural-chat-v3-3-P2-OMA',\n",
       "   'open-llm-leaderboard/details_Q-bert__MetaMath-Cybertron',\n",
       "   'open-llm-leaderboard/details_Mihaiii__Pallas-0.2',\n",
       "   'open-llm-leaderboard/details_perlthoughts__Chupacabra-8x7B-MoE',\n",
       "   'open-llm-leaderboard/details_perlthoughts__Falkor-7b',\n",
       "   'open-llm-leaderboard/details_APMIC__caigun-lora-model-34B-v3',\n",
       "   'open-llm-leaderboard/details_Mihaiii__Pallas-0.5-LASER-0.1',\n",
       "   'open-llm-leaderboard/details_rishiraj__oswald-7b',\n",
       "   'open-llm-leaderboard/details_Mihaiii__Pallas-0.4',\n",
       "   'open-llm-leaderboard/details_flemmingmiguel__Distilled-HermesChat-7B',\n",
       "   'open-llm-leaderboard/details_Weyaxi__MetaMath-OpenHermes-2.5-neural-chat-v3-3-Slerp',\n",
       "   'open-llm-leaderboard/details_Intel__neural-chat-7b-v3-3',\n",
       "   'open-llm-leaderboard/details_migtissera__Tess-M-v1.3',\n",
       "   'open-llm-leaderboard/details_fblgit__una-cybertron-7b-v2-bf16',\n",
       "   'open-llm-leaderboard/details_chargoddard__mixtralmerge-8x7B-rebalanced-test',\n",
       "   'open-llm-leaderboard/details_FelixChao__WizardDolphin-7B',\n",
       "   'open-llm-leaderboard/details_FelixChao__ExtremeDolphin-MoE',\n",
       "   'open-llm-leaderboard/details_rishiraj__oswald-2x7b',\n",
       "   'open-llm-leaderboard/details_Sao10K__Sensualize-Mixtral-bf16',\n",
       "   'open-llm-leaderboard/details_OpenBuddy__openbuddy-deepseek-67b-v15-base',\n",
       "   'open-llm-leaderboard/details_diffnamehard__Mistral-CatMacaroni-slerp-gradient',\n",
       "   'open-llm-leaderboard/details_chargoddard__servile-harpsichord-cdpo',\n",
       "   'open-llm-leaderboard/details_AA051611__limb',\n",
       "   'open-llm-leaderboard/details_adamo1139__Yi-34B-AEZAKMI-v1',\n",
       "   'open-llm-leaderboard/details_jondurbin__spicyboros-70b-2.2',\n",
       "   'open-llm-leaderboard/details_mistralai__Mixtral-8x7B-v0.1',\n",
       "   'open-llm-leaderboard/details_kyujinpy__PlatYi-34B-Llama',\n",
       "   'open-llm-leaderboard/details_nlpguy__ColorShadow-7B',\n",
       "   'open-llm-leaderboard/details_Mihaiii__Pallas-0.5-LASER-0.4',\n",
       "   'open-llm-leaderboard/details_decapoda-research__Antares-11b-v1',\n",
       "   'open-llm-leaderboard/details_Sao10K__Sensualize-Solar-10.7B',\n",
       "   'open-llm-leaderboard/details_LoSboccacc__orthogonal-2x7B-base',\n",
       "   'open-llm-leaderboard/details_Azazelle__xDAN-SlimOrca',\n",
       "   'open-llm-leaderboard/details_Mihaiii__Pallas-0.5-LASER-exp2-0.1',\n",
       "   'open-llm-leaderboard/details_kyujinpy__PlatYi-34B-200k-Q-FastChat',\n",
       "   'open-llm-leaderboard/details_Swisslex__Mixtral-Orca-v0.1',\n",
       "   'open-llm-leaderboard/details_RatanRohith__MistralBeagle-RS-7B-V0.1',\n",
       "   'open-llm-leaderboard/details_mrfakename__NeuralOrca-7B-v1',\n",
       "   'open-llm-leaderboard/details_openaccess-ai-collective__DPOpenHermes-7B',\n",
       "   'open-llm-leaderboard/details_bongchoi__MoMo-70B-LoRA-V1.1',\n",
       "   'open-llm-leaderboard/details_Praneeth__StarMix-7B-slerp',\n",
       "   'open-llm-leaderboard/details_charlesdedampierre__TopicNeuralHermes-2.5-Mistral-7B',\n",
       "   'open-llm-leaderboard/details_diffnamehard__Mistral-CatMacaroni-slerp-uncensored',\n",
       "   'open-llm-leaderboard/details_beberik__rawr',\n",
       "   'open-llm-leaderboard/details_macadeliccc__laser-dolphin-mixtral-2x7b-dpo',\n",
       "   'open-llm-leaderboard/details_perlthoughts__Starling-LM-alpha-8x7B-MoE',\n",
       "   'open-llm-leaderboard/details_perlthoughts__Chupacabra-7B-v2',\n",
       "   'open-llm-leaderboard/details_Open-Orca__Mixtral-SlimOrca-8x7B',\n",
       "   'open-llm-leaderboard/details_macadeliccc__polyglot-math-4x7b',\n",
       "   'open-llm-leaderboard/details_Sao10K__Frostwind-10.7B-v1',\n",
       "   'open-llm-leaderboard/details_Mihaiii__Pallas-0.5-LASER-0.6',\n",
       "   'open-llm-leaderboard/details_Yhyu13__LMCocktail-Mistral-7B-v1',\n",
       "   'open-llm-leaderboard/details_rombodawg__Leaderboard-killer-MoE_4x7b',\n",
       "   'open-llm-leaderboard/details_augtoma__qCammel-70x',\n",
       "   'open-llm-leaderboard/details_Doctor-Shotgun__mythospice-limarp-70b',\n",
       "   'open-llm-leaderboard/details_chargoddard__mistral-11b-slimorca',\n",
       "   'open-llm-leaderboard/details_TokenBender__pic_7B_mistral_Full_v0.1',\n",
       "   'open-llm-leaderboard/details_TomGrc__FusionNet_passthrough',\n",
       "   'open-llm-leaderboard/details_perlthoughts__Chupacabra-7B-v2.03-128k',\n",
       "   'open-llm-leaderboard/details_TomGrc__FusionNet_passthrough_v0.1',\n",
       "   'open-llm-leaderboard/details_notbdq__alooowso',\n",
       "   'open-llm-leaderboard/details_Delcos__Velara-11B-V2',\n",
       "   'open-llm-leaderboard/details_jondurbin__bagel-7b-v0.1',\n",
       "   'open-llm-leaderboard/details_Mihaiii__Metis-0.3',\n",
       "   'open-llm-leaderboard/details_perlthoughts__Chupacabra-7B-v2.03',\n",
       "   'open-llm-leaderboard/details_SanjiWatsuki__neural-chat-7b-v3-3-wizardmath-dare-me',\n",
       "   'open-llm-leaderboard/details_simonveitner__MathHermes-2.5-Mistral-7B',\n",
       "   'open-llm-leaderboard/details_cognitivecomputations__dolphin-2.2.1-mistral-7b',\n",
       "   'open-llm-leaderboard/details_bn22__OpenHermes-2.5-Mistral-7B-MISALIGNED',\n",
       "   'open-llm-leaderboard/details_jarradh__llama2_70b_chat_uncensored',\n",
       "   'open-llm-leaderboard/details_Sao10K__Euryale-L2-70B',\n",
       "   'open-llm-leaderboard/details_jondurbin__airoboros-l2-70b-gpt4-m2.0',\n",
       "   'open-llm-leaderboard/details_upstage__llama-65b-instruct',\n",
       "   'open-llm-leaderboard/details_OpenAssistant__llama2-70b-oasst-sft-v10',\n",
       "   'open-llm-leaderboard/details_elinas__chronos-70b-v2',\n",
       "   'open-llm-leaderboard/details_Neuronovo__neuronovo-7B-v0.1',\n",
       "   'open-llm-leaderboard/details_openbmb__UltraLM-65b',\n",
       "   'open-llm-leaderboard/details_jae24__openhermes_dpo_norobot_0201',\n",
       "   'open-llm-leaderboard/details_KaeriJenti__Kaori-34B-v1',\n",
       "   'open-llm-leaderboard/details_argilla__notus-7b-v1',\n",
       "   'open-llm-leaderboard/details_xxyyy123__Mistral7B_adaptor_v1',\n",
       "   'open-llm-leaderboard/details_xDAN-AI__xDAN-L1Mix-DeepThinking-v2',\n",
       "   'open-llm-leaderboard/details_liuda1__dm7b_sft_gpt88w_merge',\n",
       "   'open-llm-leaderboard/details_KnutJaegersberg__Qwen-14B-Llamafied',\n",
       "   'open-llm-leaderboard/details_HenryJJ__dolphin-2.6-mistral-7b-dpo-orca-v3',\n",
       "   'open-llm-leaderboard/details_UCLA-AGI__test',\n",
       "   'open-llm-leaderboard/details_sr5434__CodegebraGPT-10b',\n",
       "   'open-llm-leaderboard/details_upaya07__Birbal-7B-V1',\n",
       "   'open-llm-leaderboard/details_migtissera__Tess-XS-v1-3-yarn-128K',\n",
       "   'open-llm-leaderboard/details_UCLA-AGI__test0',\n",
       "   'open-llm-leaderboard/details_Azazelle__Half-NSFW_Noromaid-7b',\n",
       "   'open-llm-leaderboard/details_migtissera__Tess-7B-v1.4',\n",
       "   'open-llm-leaderboard/details_kyujinpy__PlatYi-34B-200K-Q',\n",
       "   'open-llm-leaderboard/details_chargoddard__MelangeC-70b',\n",
       "   'open-llm-leaderboard/details_spmurrayzzz__Mistral-Syndicate-7B',\n",
       "   'open-llm-leaderboard/details_dfurman__Mistral-7B-Instruct-v0.2',\n",
       "   'open-llm-leaderboard/details_huangyt__Mistral-7B-v0.1-Open-Platypus_2.5w-r16-gate_up_down',\n",
       "   'open-llm-leaderboard/details_Intel__neural-chat-7b-v3-1',\n",
       "   'open-llm-leaderboard/details_TheBloke__robin-65b-v2-fp16',\n",
       "   'open-llm-leaderboard/details_microsoft__phi-2',\n",
       "   'open-llm-leaderboard/details_WizardLM__WizardLM-70B-V1.0',\n",
       "   'open-llm-leaderboard/details_huggingface__llama-65b',\n",
       "   'open-llm-leaderboard/details_kyujinpy__PlatYi-34B-Llama-Q-v3',\n",
       "   'open-llm-leaderboard/details_Dans-DiscountModels__Dans-07YahooAnswers-7b',\n",
       "   'open-llm-leaderboard/details_OpenBuddy__openbuddy-falcon-40b-v16.1-4k',\n",
       "   'open-llm-leaderboard/details_HiTZ__alpaca-lora-65b-en-pt-es-ca',\n",
       "   'open-llm-leaderboard/details_OpenBuddyEA__openbuddy-llama-30b-v7.1-bf16',\n",
       "   'open-llm-leaderboard/details_Sao10K__Zephyrus-L1-33B',\n",
       "   'open-llm-leaderboard/details_acrastt__kalomaze-stuff',\n",
       "   'open-llm-leaderboard/details_HenryJJ__Instruct_Mistral-7B-v0.1_Dolly15K',\n",
       "   'open-llm-leaderboard/details_speechlessai__speechless-mistral-7b-dare-0.85',\n",
       "   'open-llm-leaderboard/details_diffnamehard__Psyfighter2-Noromaid-ties-Capybara-13B',\n",
       "   'open-llm-leaderboard/details_CallComply__SOLAR-10.7B-Instruct-v1.0-128k',\n",
       "   'open-llm-leaderboard/details_teknium__CollectiveCognition-v1-Mistral-7B',\n",
       "   'open-llm-leaderboard/details_Mihaiii__Metis-0.1',\n",
       "   'open-llm-leaderboard/details_CallComply__Starling-LM-11B-alpha',\n",
       "   'open-llm-leaderboard/details_jilp00__Hermes-2-SOLAR-10.7B-Symbolic',\n",
       "   'open-llm-leaderboard/details_crumb__apricot-wildflower-20',\n",
       "   'open-llm-leaderboard/details_Locutusque__Orca-2-13B-no_robots',\n",
       "   'open-llm-leaderboard/details_maywell__Synatra-RP-Orca-2-7b-v0.1',\n",
       "   'open-llm-leaderboard/details_hywu__Camelidae-8x13B',\n",
       "   'open-llm-leaderboard/details_migtissera__SynthIA-7B-v1.3',\n",
       "   'open-llm-leaderboard/details_SuperAGI__SAM',\n",
       "   'open-llm-leaderboard/details_maywell__Synatra-7B-v0.3-RP',\n",
       "   'open-llm-leaderboard/details_bofenghuang__vigostral-7b-chat',\n",
       "   'open-llm-leaderboard/details_abdulrahman-nuzha__finetuned-Mistral-5000-v1.0',\n",
       "   'open-llm-leaderboard/details_lilloukas__Platypus-30B',\n",
       "   'open-llm-leaderboard/details_osanseviero__mistral-instruct-frankenmerge',\n",
       "   'open-llm-leaderboard/details_akjindal53244__Mistral-7B-v0.1-Open-Platypus',\n",
       "   'open-llm-leaderboard/details_jondurbin__airoboros-m-7b-3.1.2',\n",
       "   'open-llm-leaderboard/details_Aeala__GPT4-x-AlpacaDente2-30b',\n",
       "   'open-llm-leaderboard/details_PeanutJar__Mistral-v0.1-PeanutButter-v0.0.2-7B',\n",
       "   'open-llm-leaderboard/details_CobraMamba__mamba-gpt-7b-v1',\n",
       "   'open-llm-leaderboard/details_umd-zhou-lab__claude2-alpaca-13B',\n",
       "   'open-llm-leaderboard/details_Undi95__MLewd-ReMM-L2-Chat-20B',\n",
       "   'open-llm-leaderboard/details_Aspik101__trurl-2-13b-pl-instruct_unload',\n",
       "   'open-llm-leaderboard/details_ajibawa-2023__Uncensored-Frank-33B',\n",
       "   'open-llm-leaderboard/details_martyn__llama-megamerge-dare-13b',\n",
       "   'open-llm-leaderboard/details_Sao10K__Stheno-1.8-L2-13B',\n",
       "   'open-llm-leaderboard/details_Undi95__Mistral-11B-v0.1',\n",
       "   'open-llm-leaderboard/details_martyn__llama2-megamerge-dare-13b-v2',\n",
       "   'open-llm-leaderboard/details_oh-yeontaek__llama-2-13B-LoRA-assemble',\n",
       "   'open-llm-leaderboard/details_JosephusCheung__Pwen-14B-Chat-20_30',\n",
       "   'open-llm-leaderboard/details_Zangs3011__mistral_7b_DolphinCoder',\n",
       "   'open-llm-leaderboard/details_l3utterfly__mistral-7b-v0.1-layla-v1',\n",
       "   'open-llm-leaderboard/details_alignment-handbook__zephyr-7b-sft-full',\n",
       "   'open-llm-leaderboard/details_PocketDoc__Dans-AdventurousWinds-7b',\n",
       "   'open-llm-leaderboard/details_SkunkworksAI__Mistralic-7B-1',\n",
       "   'open-llm-leaderboard/details_Sao10K__BrainDerp2',\n",
       "   'open-llm-leaderboard/details_PulsarAI__2x-LoRA-Assemble-Nova-13B',\n",
       "   'open-llm-leaderboard/details_Undi95__MLewd-Chat-v2-13B',\n",
       "   'open-llm-leaderboard/details_jondurbin__airoboros-33b-gpt4-m2.0',\n",
       "   'open-llm-leaderboard/details_Undi95__ReMM-v2.2-L2-13B',\n",
       "   'open-llm-leaderboard/details_stabilityai__StableBeluga-13B',\n",
       "   'open-llm-leaderboard/details_WebraftAI__synapsellm-7b-mistral-v0.3-preview',\n",
       "   'open-llm-leaderboard/details_TheBloke__OpenOrca-Platypus2-13B-GPTQ',\n",
       "   'open-llm-leaderboard/details_huggingface__llama-30b',\n",
       "   'open-llm-leaderboard/details_Undi95__Emerald-13B',\n",
       "   'open-llm-leaderboard/details_TIGER-Lab__TIGERScore-13B',\n",
       "   'open-llm-leaderboard/details_Undi95__ReMM-v2.1-L2-13B',\n",
       "   'open-llm-leaderboard/details_chargoddard__storytime-13b',\n",
       "   'open-llm-leaderboard/details_BELLE-2__BELLE-Llama2-13B-chat-0.4M',\n",
       "   'open-llm-leaderboard/details_Brouz__Slerpeno',\n",
       "   'open-llm-leaderboard/details_PulsarAI__EnsembleV5-Nova-13B',\n",
       "   'open-llm-leaderboard/details_SciPhi__SciPhi-Self-RAG-Mistral-7B-32k',\n",
       "   'open-llm-leaderboard/details_Sao10K__Stheno-L2-13B',\n",
       "   'open-llm-leaderboard/details_uukuguy__speechless-code-mistral-7b-v2.0',\n",
       "   'open-llm-leaderboard/details_Gryphe__MythoMix-L2-13b',\n",
       "   'open-llm-leaderboard/details_Aspik101__StableBeluga-13B-instruct-PL-lora_unload',\n",
       "   'open-llm-leaderboard/details_Locutusque__Orca-2-13b-SFT-v6',\n",
       "   'open-llm-leaderboard/details_Austism__chronos-hermes-13b-v2',\n",
       "   'open-llm-leaderboard/details_The-Face-Of-Goonery__Huginn-13b-v1.2',\n",
       "   'open-llm-leaderboard/details_The-Face-Of-Goonery__huginnv1.2',\n",
       "   'open-llm-leaderboard/details_Undi95__Nous-Hermes-13B-Code',\n",
       "   'open-llm-leaderboard/details_YeungNLP__firefly-llama2-13b-v1.2',\n",
       "   'open-llm-leaderboard/details_Danielbrdz__Barcenas-13b',\n",
       "   'open-llm-leaderboard/details_lu-vae__llama2-13B-sharegpt4-orca-openplatypus-8w',\n",
       "   'open-llm-leaderboard/details_defog__sqlcoder-34b-alpha',\n",
       "   'open-llm-leaderboard/details_kingbri__chronolima-airo-grad-l2-13B',\n",
       "   'open-llm-leaderboard/details_Expert68__llama2_13b_instructed_version2',\n",
       "   'open-llm-leaderboard/details_mosaicml__mpt-30b-chat',\n",
       "   'open-llm-leaderboard/details_TFLai__Luban-Platypus2-13B-QLora-0.80-epoch',\n",
       "   'open-llm-leaderboard/details_ewqr2130__mistral-se-inst-ppo',\n",
       "   'open-llm-leaderboard/details_elinas__chronos-13b-v2',\n",
       "   'open-llm-leaderboard/details_Aspik101__vicuna-13b-v1.5-PL-lora_unload',\n",
       "   'open-llm-leaderboard/details_Sao10K__Mythical-Destroyer-V2-L2-13B',\n",
       "   'open-llm-leaderboard/details_jondurbin__airoboros-c34b-2.2.1',\n",
       "   'open-llm-leaderboard/details_PygmalionAI__pygmalion-2-13b',\n",
       "   'open-llm-leaderboard/details_ajibawa-2023__Python-Code-33B',\n",
       "   'open-llm-leaderboard/details_duliadotio__dulia-13b-8k-alpha',\n",
       "   'open-llm-leaderboard/details_lmsys__vicuna-13b-v1.5-16k',\n",
       "   'open-llm-leaderboard/details_WebraftAI__synapsellm-7b-mistral-v0.4-preview3',\n",
       "   'open-llm-leaderboard/details_digitous__13B-Chimera',\n",
       "   'open-llm-leaderboard/details_The-Face-Of-Goonery__Huginn-13b-FP16',\n",
       "   'open-llm-leaderboard/details_openaccess-ai-collective__manticore-13b',\n",
       "   'open-llm-leaderboard/details_ehartford__Samantha-1.11-CodeLlama-34b',\n",
       "   'open-llm-leaderboard/details_The-Face-Of-Goonery__Chronos-Beluga-v2-13bfp16',\n",
       "   'open-llm-leaderboard/details_elyza__ELYZA-japanese-Llama-2-13b-instruct',\n",
       "   'open-llm-leaderboard/details_Secbone__llama-2-13B-instructed',\n",
       "   'open-llm-leaderboard/details_TFLai__Nous-Hermes-Platypus2-13B-QLoRA-0.80-epoch',\n",
       "   'open-llm-leaderboard/details_BAAI__Aquila2-34B',\n",
       "   'open-llm-leaderboard/details_CallComply__zephyr-7b-beta-128k',\n",
       "   'open-llm-leaderboard/details_CHIH-HUNG__llama-2-13b-huangyt_Fintune_1_17w-q_k_v_o_proj',\n",
       "   'open-llm-leaderboard/details_CHIH-HUNG__llama-2-13b-FINETUNE3_3.3w-r16-gate_up_down',\n",
       "   'open-llm-leaderboard/details_totally-not-an-llm__EverythingLM-13b-V3-peft',\n",
       "   'open-llm-leaderboard/details_budecosystem__genz-13b-v2',\n",
       "   'open-llm-leaderboard/details_CHIH-HUNG__llama-2-13b-FINETUNE1_17w-r4',\n",
       "   'open-llm-leaderboard/details_TheBloke__Wizard-Vicuna-13B-Uncensored-HF',\n",
       "   'open-llm-leaderboard/details_hfl__chinese-alpaca-2-13b-16k',\n",
       "   'open-llm-leaderboard/details_CHIH-HUNG__llama-2-13b-FINETUNE4_3.8w-r8-q_k_v_o',\n",
       "   'open-llm-leaderboard/details_TheBloke__airoboros-13B-HF',\n",
       "   'open-llm-leaderboard/details_jondurbin__airoboros-13b',\n",
       "   'open-llm-leaderboard/details_ehartford__based-30b',\n",
       "   'open-llm-leaderboard/details_Weyaxi__Platypus-Nebula-v2-7B',\n",
       "   'open-llm-leaderboard/details_euclaise__Ferret-7B',\n",
       "   'open-llm-leaderboard/details_zyh3826__llama2-13b-ft-openllm-leaderboard-v1',\n",
       "   'open-llm-leaderboard/details_Envoid__Libra-19B',\n",
       "   'open-llm-leaderboard/details_NobodyExistsOnTheInternet__GiftedConvo13bLoraNoEconsE4',\n",
       "   'open-llm-leaderboard/details_CHIH-HUNG__llama-2-13b-FINETUNE3_3.3w-r8-gate_up_down',\n",
       "   'open-llm-leaderboard/details_CHIH-HUNG__llama-2-13b-huangyt_FINETUNE2_3w',\n",
       "   'open-llm-leaderboard/details_shareAI__bimoGPT-llama2-13b',\n",
       "   'open-llm-leaderboard/details_chargoddard__llama2-22b-blocktriangular',\n",
       "   'open-llm-leaderboard/details_KnutJaegersberg__deacon-13b',\n",
       "   'open-llm-leaderboard/details_ehartford__WizardLM-1.0-Uncensored-CodeLlama-34b',\n",
       "   'open-llm-leaderboard/details_IGeniusDev__llama13B-quant8-testv1-openorca-customdataset',\n",
       "   'open-llm-leaderboard/details_psmathur__orca_mini_v3_7b',\n",
       "   'open-llm-leaderboard/details_TigerResearch__tigerbot-13b-base',\n",
       "   'open-llm-leaderboard/details_Aeala__GPT4-x-Alpasta-13b',\n",
       "   'open-llm-leaderboard/details_CHIH-HUNG__llama-2-13b-FINETUNE5_4w-r4-q_k_v_o',\n",
       "   'open-llm-leaderboard/details_kevinpro__Vicuna-13B-CoT',\n",
       "   'open-llm-leaderboard/details_AdaptLLM__finance-chat',\n",
       "   'open-llm-leaderboard/details_meta-math__MetaMath-Llemma-7B',\n",
       "   'open-llm-leaderboard/details_TFLai__Airboros2.1-Platypus2-13B-QLora-0.80-epoch',\n",
       "   'open-llm-leaderboard/details_Undi95__MLewd-L2-13B',\n",
       "   'open-llm-leaderboard/details_wei123602__llama2-13b-FINETUNE3_TEST',\n",
       "   'open-llm-leaderboard/details_KnutJaegersberg__Walter-Mistral-7B',\n",
       "   'open-llm-leaderboard/details_xzuyn__Alpacino-SuperCOT-13B',\n",
       "   'open-llm-leaderboard/details_dhmeltzer__Llama-2-13b-hf-ds_wiki_1024_full_r_64_alpha_16_merged',\n",
       "   'open-llm-leaderboard/details_pe-nlp__llama-2-13b-platypus-vicuna-wizard',\n",
       "   'open-llm-leaderboard/details_HyperbeeAI__Tulpar-7b-v0',\n",
       "   'open-llm-leaderboard/details_teknium__Mistral-Trismegistus-7B',\n",
       "   'open-llm-leaderboard/details_heegyu__LIMA-13b-hf',\n",
       "   'open-llm-leaderboard/details_wahaha1987__llama_13b_sharegpt94k_fastchat',\n",
       "   'open-llm-leaderboard/details_wang7776__Llama-2-7b-chat-hf-10-sparsity',\n",
       "   'open-llm-leaderboard/details_camel-ai__CAMEL-13B-Combined-Data',\n",
       "   'open-llm-leaderboard/details_Unbabel__TowerInstruct-7B-v0.1',\n",
       "   'open-llm-leaderboard/details_beaugogh__Llama2-7b-openorca-mc-v2-dpo',\n",
       "   'open-llm-leaderboard/details_mncai__Llama2-7B-guanaco-1k',\n",
       "   'open-llm-leaderboard/details_HyperbeeAI__Tulpar-7b-v1',\n",
       "   'open-llm-leaderboard/details_OpenBuddy__openbuddy-mixtral-7bx8-v16.3-32k',\n",
       "   'open-llm-leaderboard/details_LTC-AI-Labs__L2-7b-Beluga-WVG-Test',\n",
       "   'open-llm-leaderboard/details_lmsys__vicuna-7b-v1.5',\n",
       "   'open-llm-leaderboard/details_ashercn97__manatee-7b',\n",
       "   'open-llm-leaderboard/details_umd-zhou-lab__recycled-wizardlm-7b-v2.0',\n",
       "   'open-llm-leaderboard/details_jphme__em_german_leo_mistral',\n",
       "   'open-llm-leaderboard/details_rombodawg__LosslessMegaCoder-llama2-7b-mini',\n",
       "   'open-llm-leaderboard/details_abhinand__tamil-llama-13b-instruct-v0.1',\n",
       "   'open-llm-leaderboard/details_jondurbin__airoboros-c34b-2.1',\n",
       "   'open-llm-leaderboard/details_camel-ai__CAMEL-13B-Role-Playing-Data',\n",
       "   'open-llm-leaderboard/details_Open-Orca__OpenOrca-Preview1-13B',\n",
       "   'open-llm-leaderboard/details_zarakiquemparte__kuchiki-l2-7b',\n",
       "   'open-llm-leaderboard/details_Locutusque__Rhino-Mistral-7B',\n",
       "   'open-llm-leaderboard/details_LTC-AI-Labs__L2-7b-Synthia-WVG-Test',\n",
       "   'open-llm-leaderboard/details_TheBloke__koala-13B-HF',\n",
       "   'open-llm-leaderboard/details_PygmalionAI__pygmalion-2-7b',\n",
       "   'open-llm-leaderboard/details_deepseek-ai__deepseek-moe-16b-base',\n",
       "   'open-llm-leaderboard/details_AlekseyKorshuk__vic15-exp-syn-fight-cp3838',\n",
       "   'open-llm-leaderboard/details_davzoku__cria-llama2-7b-v1.3',\n",
       "   'open-llm-leaderboard/details_YeungNLP__firefly-llama2-13b-pretrain',\n",
       "   'open-llm-leaderboard/details_wang7776__Mistral-7B-Instruct-v0.2-sparsity-20',\n",
       "   'open-llm-leaderboard/details_DopeorNope__LaOT',\n",
       "   'open-llm-leaderboard/details_maximuslee07__llama-2-7b-rockwell-final',\n",
       "   'open-llm-leaderboard/details_922-CA__monika-ddlc-7b-v1',\n",
       "   'open-llm-leaderboard/details_openthaigpt__openthaigpt-1.0.0-beta-13b-chat-hf',\n",
       "   'open-llm-leaderboard/details_NewstaR__Koss-7B-chat',\n",
       "   'open-llm-leaderboard/details_Charlie911__vicuna-7b-v1.5-lora-timedial',\n",
       "   'open-llm-leaderboard/details_TheBloke__tulu-7B-fp16',\n",
       "   'open-llm-leaderboard/details_kashif__stack-llama-2',\n",
       "   'open-llm-leaderboard/details_haoranxu__ALMA-13B',\n",
       "   'open-llm-leaderboard/details_togethercomputer__Llama-2-7B-32K-Instruct',\n",
       "   'open-llm-leaderboard/details_TinyPixel__testmodel2',\n",
       "   'open-llm-leaderboard/details_WizardLM__WizardMath-7B-V1.0',\n",
       "   'open-llm-leaderboard/details_Charlie911__vicuna-7b-v1.5-lora-mixed-datasets-time-unit',\n",
       "   'open-llm-leaderboard/details_bongchoi__test-llama2-7b',\n",
       "   'open-llm-leaderboard/details_TaylorAI__Flash-Llama-7B',\n",
       "   'open-llm-leaderboard/details_luffycodes__vicuna-class-shishya-ac-hal-13b-ep3',\n",
       "   'open-llm-leaderboard/details_HuggingFaceH4__starchat-beta',\n",
       "   'open-llm-leaderboard/details_clibrain__Llama-2-7b-ft-instruct-es',\n",
       "   'open-llm-leaderboard/details_dotvignesh__perry-7b',\n",
       "   'open-llm-leaderboard/details_heegyu__LIMA2-7b-hf',\n",
       "   'open-llm-leaderboard/details_PocketDoc__Dans-RetroRodeo-13b',\n",
       "   'open-llm-leaderboard/details_martyn__mistral-megamerge-dare-7b',\n",
       "   'open-llm-leaderboard/details_dhmeltzer__llama-7b-SFT_ds_wiki65k_1024_r_64_alpha_16_merged',\n",
       "   'open-llm-leaderboard/details_GOAT-AI__GOAT-7B-Community',\n",
       "   'open-llm-leaderboard/details_jondurbin__airoboros-7b-gpt4-1.1',\n",
       "   'open-llm-leaderboard/details_llm-agents__tora-7b-v1.0',\n",
       "   'open-llm-leaderboard/details_cognitivecomputations__yayi2-30b-llama',\n",
       "   'open-llm-leaderboard/details_TheBloke__Wizard-Vicuna-7B-Uncensored-HF',\n",
       "   'open-llm-leaderboard/details_jondurbin__airoboros-l2-7b-gpt4-m2.0',\n",
       "   'open-llm-leaderboard/details_DevaMalla__llama_7b_qlora_pds-eval',\n",
       "   'open-llm-leaderboard/details_webbigdata__ALMA-7B-Ja-V2',\n",
       "   'open-llm-leaderboard/details_bofenghuang__vigogne-7b-instruct',\n",
       "   'open-llm-leaderboard/details_Neko-Institute-of-Science__metharme-7b',\n",
       "   'open-llm-leaderboard/details_jondurbin__airoboros-7b',\n",
       "   'open-llm-leaderboard/details_h2m__mhm-7b-v1.3',\n",
       "   'open-llm-leaderboard/details_Undi95__Mixtral-8x7B-MoE-RP-Story',\n",
       "   'open-llm-leaderboard/details_itsliupeng__openllama-7b-base',\n",
       "   'open-llm-leaderboard/details_ausboss__llama7b-wizardlm-unfiltered',\n",
       "   'open-llm-leaderboard/details_DevaMalla__llama_7b_lora',\n",
       "   'open-llm-leaderboard/details_ehartford__dolphin-2.2-yi-34b-200k',\n",
       "   'open-llm-leaderboard/details_cognitivecomputations__dolphin-2.2-yi-34b-200k',\n",
       "   'open-llm-leaderboard/details_jondurbin__airoboros-7b-gpt4-1.4.1-qlora',\n",
       "   'open-llm-leaderboard/details_YeungNLP__firefly-llama2-7b-pretrain',\n",
       "   'open-llm-leaderboard/details_fireballoon__baichuan-vicuna-chinese-7b',\n",
       "   'open-llm-leaderboard/details_vikash06__mistral_v1',\n",
       "   'open-llm-leaderboard/details_huggingface__llama-7b',\n",
       "   'open-llm-leaderboard/details_yeontaek__WizardCoder-Python-13B-LoRa',\n",
       "   'open-llm-leaderboard/details_Charlie911__vicuna-7b-v1.5-lora-mctaco-modified1',\n",
       "   'open-llm-leaderboard/details_ashercn97__giraffe-7b',\n",
       "   'open-llm-leaderboard/details_luffycodes__llama-shishya-7b-ep3-v1',\n",
       "   'open-llm-leaderboard/details_shareAI__CodeLLaMA-chat-13b-Chinese',\n",
       "   'open-llm-leaderboard/details_KnutJaegersberg__Qwen-1_8B-Llamafied',\n",
       "   'open-llm-leaderboard/details_WeOpenML__Alpaca-7B-v1',\n",
       "   'open-llm-leaderboard/details_mosaicml__mpt-7b',\n",
       "   'open-llm-leaderboard/details_togethercomputer__GPT-JT-6B-v0',\n",
       "   'open-llm-leaderboard/details_hyunseoki__ko-ref-llama2-13b',\n",
       "   'open-llm-leaderboard/details_cyberagent__calm2-7b-chat',\n",
       "   'open-llm-leaderboard/details_FreedomIntelligence__phoenix-inst-chat-7b',\n",
       "   'open-llm-leaderboard/details_Pierre-obi__Mistral_solar-slerp',\n",
       "   'open-llm-leaderboard/details_qblocks__codellama_7b_DolphinCoder',\n",
       "   'open-llm-leaderboard/details_openlm-research__open_llama_7b',\n",
       "   'open-llm-leaderboard/details_klosax__open_llama_13b_600bt_preview',\n",
       "   'open-llm-leaderboard/details_wenge-research__yayi-7b',\n",
       "   'open-llm-leaderboard/details_glaiveai__glaive-coder-7b',\n",
       "   'open-llm-leaderboard/details_uukuguy__speechless-coder-ds-6.7b',\n",
       "   'open-llm-leaderboard/details_digitous__Javalion-R',\n",
       "   'open-llm-leaderboard/details_NousResearch__CodeLlama-34b-hf',\n",
       "   'open-llm-leaderboard/details_codellama__CodeLlama-7b-hf',\n",
       "   'open-llm-leaderboard/details_heegyu__RedTulu-Uncensored-3B-0719']])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['models']),data['models'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d8135b-e9ec-468a-85a7-3cd3fc3d31fe",
   "metadata": {},
   "source": [
    "Below, we will process the data so all correctness scores (for all scenarios) are stored in $Y$. The dictionaries `scenarios_position` and `subscenarios_position` give the position of scenarios/subscenarios correctness scores in $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee09c25b-2dc4-4403-a972-9fb05cfe917b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393, 13350)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios_position, subscenarios_position = prepare_data(lb_scenarios, data)\n",
    "Y = create_responses(lb_scenarios, data)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e002485a-1e82-409b-aaf2-ddb6a82bc315",
   "metadata": {},
   "source": [
    "For example, below you can see the scores for MMLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c4dd9649-ba75-49c0-92fe-b00d2afc252e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.99999999, 0.99994655, 1.        , ..., 1.        , 0.        ,\n",
       "         1.        ],\n",
       "        [0.99984026, 0.99999999, 0.99908489, ..., 1.        , 1.        ,\n",
       "         1.        ],\n",
       "        [0.99937792, 0.99999997, 0.99732544, ..., 1.        , 1.        ,\n",
       "         1.        ],\n",
       "        ...,\n",
       "        [0.59677787, 0.99801392, 0.20934594, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.67288482, 0.99814252, 0.3865014 , ..., 0.        , 1.        ,\n",
       "         1.        ],\n",
       "        [0.42345796, 0.99926741, 0.82057698, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " (393, 13350))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:,scenarios_position['lb']], Y[:,scenarios_position['lb']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aa753f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y stats:\n",
      "min: 0.0\n",
      "max: 1.0000000000000002\n",
      "mean: 0.7231160348021274\n",
      "std: 0.443520043003996\n"
     ]
    }
   ],
   "source": [
    "# fill nan values with 0\n",
    "Y[np.isnan(Y)] = 0\n",
    "\n",
    "# print stats of Y\n",
    "print('Y stats:')\n",
    "print('min:', np.min(Y))\n",
    "print('max:', np.max(Y))\n",
    "print('mean:', np.mean(Y))\n",
    "print('std:', np.std(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662681a7-10b0-4ddc-a692-52d278499539",
   "metadata": {},
   "source": [
    "For scenarios that have multiple subscenarios, it is usually the case that we want to give equal importance to individual subscenarios when computing the aggregated performance in that scenario. This is equivalent to using a weighted average when computing the aggregated performance. We will create `balance_weights`, a vector of weights to help us compute those weighted averages. These weights will be different than one only for MMLU, which is the only scenario with multiple subscenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1f40fc53-b11e-41cc-adc2-7abff1a2b368",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_weights = np.ones(Y.shape[1])\n",
    "\n",
    "selected_scenarios = lb_scenarios['lb']\n",
    "\n",
    "N = len(scenarios_position['lb'])\n",
    "n_sub = len(selected_scenarios)\n",
    "for sub in selected_scenarios:\n",
    "    n_i = len(subscenarios_position['lb'][sub])\n",
    "    balance_weights[subscenarios_position['lb'][sub]] = N/(n_sub*n_i)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971d42b7-c6ac-4695-a5f0-3087c091d16d",
   "metadata": {},
   "source": [
    "We can see below that first averaging within subscenarios and then computing a simple average is equivalent to using a weighted average from the beginning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b7b51b6f-5ce5-46bf-ba44-836386db05f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1356762293373007e-14"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs1 = np.mean([Y[:,subscenarios_position['lb'][sub]].mean(axis=1) for sub in lb_scenarios['lb']], axis=0)\n",
    "accs2 = (balance_weights*Y)[:,scenarios_position['lb']].mean(axis=1)\n",
    "\n",
    "np.abs(accs1 - accs2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d106b620-7fe0-49bb-a8ac-3a946c15f751",
   "metadata": {},
   "source": [
    "## Getting and using anchor points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844c4412-ae69-4184-b106-191a1c151736",
   "metadata": {},
   "source": [
    "Let's split the data in train and test (recent models are placed in the test set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dc9874c5-7cb5-425b-8c41-9a87d7615ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = Y[:100]\n",
    "Y_train = Y[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f485b83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6547273254796847"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(balance_weights*Y_train)[:,scenarios_position['lb']].mean(axis=1).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8680d6e6-1ec2-4a24-a898-f29bd5ec109e",
   "metadata": {},
   "source": [
    "The variable `number_item` gives the number of anchor points we want to find in each scenario:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a528f89a-64bb-497e-b993-9181996d75d1",
   "metadata": {},
   "source": [
    "The variable `clustering` specified how the clusting is run. If `clustering=\"correct.\"`, then correctness is used. On the other hand, if `clustering=\"irt\"`, then the IRT embeddings for examples are used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5edf1d-21b3-46f9-9034-479ebe89314d",
   "metadata": {},
   "source": [
    "Computing anchor points and their weights for each scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "313c85b8-838d-416c-ac7d-e40725e08853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_anchor_points(clustering, lb_scenarios, scenarios_position, balance_weights, Y_train, number_item, random_state):\n",
    "    anchor_points = {}\n",
    "    anchor_weights = {}\n",
    "\n",
    "    for scenario in lb_scenarios.keys():\n",
    "\n",
    "        if clustering=='correct.':\n",
    "            X = Y_train[:,scenarios_position[scenario]].T\n",
    "        elif clustering=='irt':\n",
    "            A, B, _ = load_irt_parameters('data/irt_model/')\n",
    "            X = np.vstack((A.squeeze(), B.squeeze().reshape((1,-1)))).T\n",
    "            X = X[scenarios_position[scenario]]\n",
    "        else:\n",
    "            raise NotImplementedError \n",
    "            \n",
    "        #Normalizing balance_weights, so their sum is one within each scenario\n",
    "        norm_balance_weights = balance_weights[scenarios_position[scenario]]\n",
    "        norm_balance_weights /= norm_balance_weights.sum()\n",
    "\n",
    "        # Fitting the KMeans model\n",
    "        kmeans = KMeans(n_clusters=number_item, n_init=\"auto\", random_state=random_state)\n",
    "        kmeans.fit(X, sample_weight=norm_balance_weights)\n",
    "\n",
    "        # Calculating anchor points\n",
    "        anchor_points[scenario] = pairwise_distances(kmeans.cluster_centers_, X, metric='euclidean').argmin(axis=1)\n",
    "\n",
    "        # Calculating anchor weights\n",
    "        anchor_weights[scenario] = np.array([np.sum(norm_balance_weights[kmeans.labels_==c]) for c in range(number_item)])\n",
    "\n",
    "    return anchor_points, anchor_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c071b44-1410-4cb8-9d20-2f5a3ed9c5c9",
   "metadata": {},
   "source": [
    "Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "11008304-b6db-4b55-863d-c9968a0b76ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = 'irt' # 'correct.' or 'irt'\n",
    "\n",
    "for anchor_num in [10, 15, 20, 30, 50]:\n",
    "    anchor_points, anchor_weights = compute_anchor_points(clustering, lb_scenarios, scenarios_position, balance_weights, Y_train, anchor_num, random_state)\n",
    "    anchor = {'anchor_points':anchor_points,\n",
    "            'anchor_weights':anchor_weights}\n",
    "\n",
    "    # save to tinybenchmark_lb file, putting 'seen_examples', 'examples_weights', 'irt_parameters', 'scenarios_position', 'subscenarios_position', 'optimal_lambdas'\n",
    "    tinybenchmark_lb = {'seen_examples':anchor_points,\n",
    "                        'examples_weights':anchor_weights,\n",
    "                        'scenarios_position':scenarios_position,\n",
    "                        'subscenarios_position':subscenarios_position,\n",
    "                        }\n",
    "\n",
    "    with open(f'data/lb_anchor_{anchor_num}.pickle', 'wb') as handle:\n",
    "        pickle.dump(tinybenchmark_lb, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651edaf8-af28-4e6f-92d6-192477c0aa44",
   "metadata": {},
   "source": [
    "Checking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5a468b8f-950b-41c5-b009-e9b3d913b0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lb': array([  865,  7421,   413,  2193,   449,  1290,   511,   227,   698,\n",
       "         7286,  1277,  7663,   746,  5910, 12947,  2866, 12972,  5336,\n",
       "         5912,   470,  1766,  1193,   615,  6103,   124,  1622,  1068,\n",
       "          831,  1167,  3164,  2968,  3042,  9778,  2678, 10076,  6063,\n",
       "         1863,    55, 10614,  5644,  3361,  4207,  3833,  8169, 10490,\n",
       "          247,  1680,  1762,   484,  2472])}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tinybenchmark_lb['seen_examples']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ac7f2a-9288-4ef5-aa57-7280523cfd4c",
   "metadata": {},
   "source": [
    "Using anchor points to estimate performance in the test set and reporting the average prediction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4a79301f-1140-474e-bd41-832f9c6d0332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario: lb, avg. error: 0.031\n"
     ]
    }
   ],
   "source": [
    "for scenario in lb_scenarios.keys():\n",
    "    Y_anchor = Y_test[:,scenarios_position[scenario]][:,anchor_points[scenario]]\n",
    "    Y_hat = (Y_anchor*anchor_weights[scenario]).sum(axis=1)\n",
    "    Y_true = (balance_weights*Y_test)[:,scenarios_position[scenario]].mean(axis=1)\n",
    "\n",
    "    print(f\"scenario: {scenario}, avg. error: {np.abs(Y_hat-Y_true).mean():.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
